{
  
    
        "post0": {
            "title": "Camvid-Imdb-example-Fastai",
            "content": "!pip install fastai2 --quiet . !pip install nbdev !pip install fastcore . Collecting nbdev Downloading nbdev-0.2.18-py3-none-any.whl (45 kB) |████████████████████████████████| 45 kB 992 kB/s eta 0:00:011 Collecting fastscript Downloading fastscript-0.1.4-py3-none-any.whl (11 kB) Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from nbdev) (20.1) Requirement already satisfied: nbconvert&gt;=5.6.1 in /opt/conda/lib/python3.7/site-packages (from nbdev) (5.6.1) Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from nbdev) (5.3.1) Requirement already satisfied: nbformat&gt;=4.4.0 in /opt/conda/lib/python3.7/site-packages (from nbdev) (5.0.6) Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging-&gt;nbdev) (1.14.0) Requirement already satisfied: pyparsing&gt;=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging-&gt;nbdev) (2.4.7) Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (2.6.1) Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (0.4.4) Requirement already satisfied: jinja2&gt;=2.4 in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (2.11.2) Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (3.1.4) Requirement already satisfied: traitlets&gt;=4.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (4.3.3) Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (0.6.0) Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (0.8.4) Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (4.6.3) Requirement already satisfied: entrypoints&gt;=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (0.3) Requirement already satisfied: pandocfilters&gt;=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert&gt;=5.6.1-&gt;nbdev) (1.4.2) Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (0.2.0) Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (3.2.0) Requirement already satisfied: MarkupSafe&gt;=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2&gt;=2.4-&gt;nbconvert&gt;=5.6.1-&gt;nbdev) (1.1.1) Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach-&gt;nbconvert&gt;=5.6.1-&gt;nbdev) (0.5.1) Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets&gt;=4.2-&gt;nbconvert&gt;=5.6.1-&gt;nbdev) (4.4.2) Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (46.1.3.post20200325) Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (1.6.0) Requirement already satisfied: pyrsistent&gt;=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (0.16.0) Requirement already satisfied: attrs&gt;=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (19.3.0) Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (3.1.0) Installing collected packages: fastscript, nbdev Successfully installed fastscript-0.1.4 nbdev-0.2.18 Requirement already satisfied: fastcore in /opt/conda/lib/python3.7/site-packages (0.1.18) Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fastcore) (1.18.5) . from fastai2.vision.all import * . # gathering the dataset path = untar_data(URLs.CAMVID_TINY) . dls = SegmentationDataLoaders.from_label_func(path, bs= 64, fnames= get_image_files(path/&quot;images&quot;), label_func= lambda o:path/&#39;labels&#39;/f&#39;{o.stem}_P{o.suffix}&#39;, codes= np.loadtxt(path/&#39;codes.txt&#39;, dtype=str) ) . import functools, traceback class gpu_mem_restore_ctx(): &quot; context manager to reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted&quot; def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): if not exc_val: return True traceback.clear_frames(exc_tb) raise exc_type(exc_val).with_traceback(exc_tb) from None . learn = unet_learner(dls, resnet34) . learn.fine_tune(8) . epoch train_loss valid_loss time . 0 | 3.736854 | 3.571304 | 00:00 | . epoch train_loss valid_loss time . 0 | 3.582396 | 3.382562 | 00:00 | . 1 | 3.461463 | 3.738088 | 00:00 | . 2 | 3.229613 | 2.772933 | 00:00 | . 3 | 3.056785 | 27.153690 | 00:00 | . 4 | 5.184041 | 4.426192 | 00:00 | . 5 | 4.995150 | 2.705719 | 00:00 | . 6 | 4.614924 | 2.713920 | 00:00 | . 7 | 4.330629 | 2.718229 | 00:00 | . with gpu_mem_restore_ctx(): learn.fine_tune(10) . epoch train_loss valid_loss time . 0 | 3.543984 | 3.283773 | 00:04 | . epoch train_loss valid_loss time . 0 | 3.335565 | 2.785197 | 00:00 | . 1 | 3.104301 | 15.021441 | 00:00 | . 2 | 4.845769 | 4.041796 | 00:00 | . 3 | 4.655784 | 2.902167 | 00:00 | . 4 | 4.267091 | 2.794876 | 00:00 | . 5 | 3.980669 | 2.747960 | 00:00 | . 6 | 3.766608 | 2.455791 | 00:00 | . 7 | 3.571517 | 2.385206 | 00:00 | . 8 | 3.409564 | 2.313739 | 00:00 | . 9 | 3.269744 | 2.286877 | 00:00 | . learn.show_results(max_n = 9, figsize=(8, 8)) . NLP text example . from fastai2.text.all import * . path2 = untar_data(URLs.IMDB) . textdls = TextDataLoaders.from_folder(path2, valid = &#39;test&#39;) . textlearner = text_classifier_learner(textdls, AWD_LSTM, drop_mult= .5, metrics = accuracy) . with gpu_mem_restore_ctx(): textlearner.fine_tune(4, 1e-2) . epoch train_loss valid_loss accuracy time . 0 | 0.607154 | 0.396850 | 0.817360 | 02:17 | . epoch train_loss valid_loss accuracy time . 0 | 0.343570 | 0.318869 | 0.859280 | 04:10 | . 1 | 0.247592 | 0.213031 | 0.914760 | 04:15 | . 2 | 0.198262 | 0.206739 | 0.921840 | 04:08 | . 3 | 0.189943 | 0.215887 | 0.918880 | 04:17 | . textlearner.predict(&quot;The movie was fucking great&quot;) . (&#39;pos&#39;, tensor(1), tensor([0.0649, 0.9351])) . !pip install jovian --upgrade . Collecting jovian Downloading jovian-0.2.16-py2.py3-none-any.whl (63 kB) |████████████████████████████████| 63 kB 1.1 MB/s eta 0:00:011 Collecting uuid Downloading uuid-1.30.tar.gz (5.8 kB) Requirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from jovian) (7.1.1) Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.7/site-packages (from jovian) (5.3.1) Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from jovian) (2.23.0) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;jovian) (2020.6.20) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;jovian) (1.24.3) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;jovian) (3.0.4) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;jovian) (2.9) Building wheels for collected packages: uuid Building wheel for uuid (setup.py) ... done Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6500 sha256=7e7aef5316b0b7eadf3ed3f60f954dbedb05bde3c44654e5d07a23a1603da8f9 Stored in directory: /root/.cache/pip/wheels/2a/ea/87/dd57f1ecb4f0752f3e1dbf958ebf8b36d920d190425bcdc24d Successfully built uuid Installing collected packages: uuid, jovian Successfully installed jovian-0.2.16 uuid-1.30 . import jovian project = &quot;2020-07-23-fastai-camvid-Imdb&quot; . jovian.commit(project = project) . [jovian] Attempting to save notebook.. [jovian] Detected Kaggle notebook... [jovian] Uploading notebook to https://jovian.ml/sivaramakrishnan1998/2020-07-23-fastai-camvid-Imdb .",
            "url": "https://sivaramakrishnan1998.github.io/cvmldl/beginner/2020/07/23/fastai-camvid-Imdb.html",
            "relUrl": "/beginner/2020/07/23/fastai-camvid-Imdb.html",
            "date": " • Jul 23, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "linear regression from scratch using pytorch",
            "content": "import numpy as np import torch . inputs = np.array([ [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70] ], dtype= &#39;float32&#39;) . targets = np.array([ [56, 70], [81, 101], [119, 133], [22, 37], [103, 119] ], dtype= &#39;float32&#39;) . # converting inputs and targets into tensors inputs = torch.from_numpy(inputs) targets = torch.from_numpy(targets) print (inputs) print (targets) . tensor([[ 73., 67., 43.], [ 91., 88., 64.], [ 87., 134., 58.], [102., 43., 37.], [ 69., 96., 70.]]) tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) . The first row of w and the first element of b are used to predict the first target variable i.e. yield of apples, and similarly the second for oranges. . # weights and biases w = torch.randn(2, 3, requires_grad = True) b = torch.randn(2, requires_grad= True) . print (w, b) # torch.randn creates tensor with elements mean = 0 and standard_deviation = 1 . tensor([[-0.5616, 0.8701, 1.3327], [-0.8417, 1.6244, 0.2163]], requires_grad=True) tensor([-0.3904, 1.0251], requires_grad=True) . # pred = x * w + b . def model(x): return x @ w.t() + b # @ : dot_product # .t(): takes transpose . # Generaten Predictions preds = model(inputs) . print (preds, targets) . tensor([[ 74.2108, 57.7131], [110.3599, 81.2160], [144.6323, 158.0064], [ 29.0453, -6.9796], [137.6730, 114.0266]], grad_fn=&lt;AddBackward0&gt;) tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) . loss function Mean_square error algorithm . Calculate the difference between the two matrices (preds and targets). | Square all elements of the difference matrix to remove negative values. | Calculate the average of the elements in the resulting matrix. | . def mse(t1, t2): diff = t1-t2 return torch.sum(diff*diff)/ diff.numel() # diff*diff : element wise multiplication . # compute_loss loss = mse(preds, targets) print (loss) . tensor(622.9136, grad_fn=&lt;DivBackward0&gt;) . # computing gradients loss.backward(retain_graph=True) . print (w) print (w.grad) . tensor([[-0.5616, 0.8701, 1.3327], [-0.8417, 1.6244, 0.2163]], requires_grad=True) tensor([[ 1868.4410, 2174.0151, 1367.3108], [-1070.1625, -316.3842, -463.9043]]) . w.grad.zero_() b.grad.zero_() print (w.grad, b.grad) . tensor([[0., 0., 0.], [0., 0., 0.]]) tensor([0., 0.]) . Gradient Descent Alogrithm: . * Generate predictions * Calculate the loss * Compute gradients w.r.t the weights and biases * Adjust the weights by subtracting a small quantity proportional to the gradient * Reset the gradients to zero . # calculate loss loss = mse(preds, targets) print (loss) . tensor(622.9136, grad_fn=&lt;DivBackward0&gt;) . # compute gradients loss.backward() print (w.grad) print (b.grad) . tensor([[ 1868.4410, 2174.0151, 1367.3108], [-1070.1625, -316.3842, -463.9043]]) tensor([ 22.9843, -11.2035]) . with torch.no_grad(): w -= w.grad * 1e-5 b -= b.grad * 1e-5 w.grad.zero_() b.grad.zero_() . print (w, b) . tensor([[-0.5803, 0.8483, 1.3191], [-0.8310, 1.6275, 0.2209]], requires_grad=True) tensor([-0.3907, 1.0252], requires_grad=True) . # calculating loss preds = model(inputs) loss = mse(preds, targets) print (loss) . tensor(517.4789, grad_fn=&lt;DivBackward0&gt;) . # training for multiple epochs for i in range(100): preds = model(inputs) loss = mse(preds, targets) loss.backward() with torch.no_grad(): w -= w.grad * 1e-5 b -= b.grad * 1e-5 w.grad.zero_() b.grad.zero_() . preds = model(inputs) loss = mse(preds, targets) print (loss) . tensor(112.5866, grad_fn=&lt;DivBackward0&gt;) . print (preds ) . tensor([[ 55.8683, 67.3889], [ 85.4439, 92.7072], [113.4147, 155.7666], [ 14.3398, 18.4401], [111.4086, 116.3273]], grad_fn=&lt;AddBackward0&gt;) . print (targets) . tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) .",
            "url": "https://sivaramakrishnan1998.github.io/cvmldl/beginner/2020/07/20/linear-regression-from-scratch.html",
            "relUrl": "/beginner/2020/07/20/linear-regression-from-scratch.html",
            "date": " • Jul 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sivaramakrishnan1998.github.io/cvmldl/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sivaramakrishnan1998.github.io/cvmldl/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sivaramakrishnan1998.github.io/cvmldl/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sivaramakrishnan1998.github.io/cvmldl/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}